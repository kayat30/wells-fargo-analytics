<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Wells Fargo Analytics Competition by kayat30</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Wells Fargo Analytics Competition</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.com/kayat30/wells-fargo-analytics" class="btn">View on GitHub</a>
      <a href="https://github.com/kayat30/wells-fargo-analytics/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/kayat30/wells-fargo-analytics/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="wells-fargo-analytics-competition" class="anchor" href="#wells-fargo-analytics-competition" aria-hidden="true"><span class="octicon octicon-link"></span></a>Wells Fargo Analytics Competition</h1>

<h2>
<a id="background" class="anchor" href="#background" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background</h2>

<p>Wells Fargo challenged data scientists to extract information from social media posts mentioning banks. They provided tweets and Facebook posts that included references to four banks (BankA, BankB, BankC and BankD) in order to determine what financial and bank topics consumers posted about in social media. They were also interested in the reasons consumers post about banks and whether the substance of the posts is consistent across the industry or isolated to individual banks. Specifically, they challenged data scientists to develop an approach that identifies, classifies, and extracts the underlying drivers in social media data. </p>

<p><a href="http://innercircle.engineering.asu.edu/wp-content/uploads/2015/11/Wells-Fargo-Campus-Analytic-Challenge-Information.pdf">Competition Summary</a></p>

<h2>
<a id="approach" class="anchor" href="#approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>Approach</h2>

<h3>
<a id="the-data" class="anchor" href="#the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Data</h3>

<p><img src="http://imgur.com/erexpCj" alt="Original text file"></p>

<p><img src="http://imgur.com/qprA8vl" alt="Content of posts"></p>

<p>The first step in the analytic process was to clean/preprocess the data. </p>

<div class="highlight highlight-source-r"><pre><span class="pl-v">df</span> <span class="pl-k">=</span> read.table(<span class="pl-s"><span class="pl-pds">'</span>dataset.txt<span class="pl-pds">'</span></span>,<span class="pl-v">sep</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>|<span class="pl-pds">"</span></span>,<span class="pl-v">header</span><span class="pl-k">=</span><span class="pl-c1">T</span>)
<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">FullText</span> <span class="pl-k">=</span> as.character(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>)

<span class="pl-c"># Remove non-ascii characters</span>
<span class="pl-v">df.texts.clean</span> <span class="pl-k">=</span> as.data.frame(iconv(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>, <span class="pl-s"><span class="pl-pds">"</span>latin1<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>ASCII<span class="pl-pds">"</span></span>, <span class="pl-v">sub</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>))
colnames(<span class="pl-smi">df.texts.clean</span>) <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>FullText<span class="pl-pds">'</span></span>

<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-v">FullText</span> <span class="pl-k">=</span> <span class="pl-smi">df.texts.clean</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>

<span class="pl-c">#test 10,000 texts: good sample size</span>
<span class="pl-v">idx.10000</span> <span class="pl-k">=</span> sample(<span class="pl-c1">1</span><span class="pl-k">:</span>nrow(<span class="pl-smi">df</span>),<span class="pl-c1">10000</span>)
<span class="pl-v">df.10000</span> <span class="pl-k">=</span> <span class="pl-smi">df</span>[<span class="pl-smi">idx.10000</span>,]

<span class="pl-v">df.entire</span> <span class="pl-k">=</span> <span class="pl-smi">df</span>
<span class="pl-v">df</span> <span class="pl-k">=</span> <span class="pl-smi">df.10000</span>

<span class="pl-c"># Load using the tm library</span>
library(<span class="pl-smi">tm</span>) 
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> Corpus(DataframeSource(as.data.frame(<span class="pl-smi">df</span>[,<span class="pl-c1">6</span>])))   

<span class="pl-c">#REMEMBER: IT MATTERS THE ORDER IN WHICH TM_MAP EXPRESSIONS ARE RUN</span>
library(<span class="pl-smi">rJava</span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, content_transformer(<span class="pl-smi">tolower</span>)) <span class="pl-c"># convert to lowercase first</span>
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removeWords</span>, stopwords(<span class="pl-s"><span class="pl-pds">'</span>english<span class="pl-pds">'</span></span>))
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removeWords</span>, stopwords(<span class="pl-v">kind</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>SMART<span class="pl-pds">"</span></span>))
<span class="pl-c">#metaData/recurrent words</span>
<span class="pl-smi">myMeta</span> <span class="pl-k">&lt;-</span> c(<span class="pl-s"><span class="pl-pds">"</span>name<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>bank<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>banka<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>bankb<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>bankc<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>bankd<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>banke<span class="pl-pds">"</span></span>,
            <span class="pl-s"><span class="pl-pds">"</span>internet<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>https<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>rettwit<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>twit_hndl_banka<span class="pl-pds">"</span></span>,
            <span class="pl-s"><span class="pl-pds">"</span>twit_hndl_bankb<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>twit_hndl_bankc<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>twit_hndl_bankd<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>phone<span class="pl-pds">"</span></span>,
            <span class="pl-s"><span class="pl-pds">"</span>dirmsg<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>dir_msg<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>street<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>name_resp<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>bankds<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>and<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>for<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>the<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>you<span class="pl-pds">"</span></span>,
            <span class="pl-s"><span class="pl-pds">"</span>twithndlbanka<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>dirmsg<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>ret_twit<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>twit_hndl<span class="pl-pds">"</span></span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removeWords</span>, <span class="pl-smi">myMeta</span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">stripWhitespace</span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removePunctuation</span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">PlainTextDocument</span>)

<span class="pl-smi">new.df</span> <span class="pl-k">&lt;-</span><span class="pl-k">data.frame</span>(<span class="pl-v">text</span><span class="pl-k">=</span>unlist(sapply(<span class="pl-smi">docs</span>, `[[`, <span class="pl-s"><span class="pl-pds">"</span>content<span class="pl-pds">"</span></span>)), <span class="pl-v">stringsAsFactors</span><span class="pl-k">=</span><span class="pl-c1">FALSE</span>)</pre></div>

<h3>
<a id="frequency-analysis" class="anchor" href="#frequency-analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Frequency Analysis</h3>

<p>After cleaning the data, analyzed frequent terms in posts to get a sense of what topics consumers most frequently posted about.</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">dtm</span> <span class="pl-k">&lt;-</span> DocumentTermMatrix(<span class="pl-smi">docs</span>)
<span class="pl-v">dtm</span> <span class="pl-k">=</span> removeSparseTerms(<span class="pl-smi">dtm</span>, <span class="pl-c1">0.98</span>)
findFreqTerms(<span class="pl-smi">dtm</span>,<span class="pl-c1">200</span>)

<span class="pl-smi">freq</span> <span class="pl-k">&lt;-</span> colSums(as.matrix(<span class="pl-smi">dtm</span>))  
<span class="pl-smi">freq</span>
<span class="pl-smi">ord</span> <span class="pl-k">&lt;-</span> order(<span class="pl-smi">freq</span>)   

library(<span class="pl-smi">wordcloud</span>)
wordcloud(names(<span class="pl-smi">freq</span>), <span class="pl-smi">freq</span>, <span class="pl-v">colors</span><span class="pl-k">=</span>brewer.pal(<span class="pl-c1">8</span>, <span class="pl-s"><span class="pl-pds">"</span>Dark2<span class="pl-pds">"</span></span>))</pre></div>

<p><img src="http://imgur.com/mOsebx5" alt="Word cloud of all posts"></p>

<p>Also generated word clouds for each bank </p>

<div class="highlight highlight-source-r"><pre><span class="pl-v">bankA.idx</span> <span class="pl-k">=</span> which(sapply(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>,<span class="pl-k">function</span>(<span class="pl-smi">x</span>) grepl(<span class="pl-s"><span class="pl-pds">"</span>BankA<span class="pl-pds">"</span></span>,<span class="pl-smi">x</span>)))
<span class="pl-v">bankB.idx</span> <span class="pl-k">=</span> which(sapply(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>,<span class="pl-k">function</span>(<span class="pl-smi">x</span>) grepl(<span class="pl-s"><span class="pl-pds">"</span>BankB<span class="pl-pds">"</span></span>,<span class="pl-smi">x</span>)))
<span class="pl-v">bankC.idx</span> <span class="pl-k">=</span> which(sapply(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>,<span class="pl-k">function</span>(<span class="pl-smi">x</span>) grepl(<span class="pl-s"><span class="pl-pds">"</span>BankC<span class="pl-pds">"</span></span>,<span class="pl-smi">x</span>)))
<span class="pl-v">bankD.idx</span> <span class="pl-k">=</span> which(sapply(<span class="pl-smi">df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>,<span class="pl-k">function</span>(<span class="pl-smi">x</span>) grepl(<span class="pl-s"><span class="pl-pds">"</span>BankD<span class="pl-pds">"</span></span>,<span class="pl-smi">x</span>)))

<span class="pl-v">bankA.docs</span> <span class="pl-k">=</span> <span class="pl-smi">docs</span>[<span class="pl-smi">bankA.idx</span>]
<span class="pl-v">bankB.docs</span> <span class="pl-k">=</span> <span class="pl-smi">docs</span>[<span class="pl-smi">bankB.idx</span>]
<span class="pl-v">bankC.docs</span> <span class="pl-k">=</span> <span class="pl-smi">docs</span>[<span class="pl-smi">bankC.idx</span>]
<span class="pl-v">bankD.docs</span> <span class="pl-k">=</span> <span class="pl-smi">docs</span>[<span class="pl-smi">bankD.idx</span>]

<span class="pl-c">##pass these in as argument in dtm &lt;- DocumentTermMatrix(docs)</span>
<span class="pl-c">##repeat word cloud procedure </span></pre></div>

<p><img src="http://imgur.com/qyEGLEi" alt="Bank A">
<img src="http://imgur.com/CH2lx1P" alt="Bank B">
<img src="http://imgur.com/KwXPfas" alt="Bank C">
<img src="http://imgur.com/qkAmlR3" alt="Bank D"></p>

<h3>
<a id="sentiment-analysis" class="anchor" href="#sentiment-analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sentiment Analysis</h3>

<p>Analyzed sentiment of posts to identify what drives consumers to post about banks (dissatisfaction, appreciation, etc).</p>

<p>First, used function to match words in posts with list of positive and negative words</p>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># Based on: http://www.ihub.co.ke/blogs/23216</span>
<span class="pl-c"># Download and upload: http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar</span>
<span class="pl-c">#system('unrar e opinion-lexicon-English.rar')</span>

<span class="pl-smi">pos</span> <span class="pl-k">&lt;-</span> scan(<span class="pl-s"><span class="pl-pds">'</span>positive-words.txt<span class="pl-pds">'</span></span>,<span class="pl-v">what</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>character<span class="pl-pds">'</span></span>,<span class="pl-v">comment.char</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>;<span class="pl-pds">'</span></span>)
<span class="pl-smi">neg</span> <span class="pl-k">&lt;-</span> scan(<span class="pl-s"><span class="pl-pds">'</span>negative-words.txt<span class="pl-pds">'</span></span>,<span class="pl-v">what</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>character<span class="pl-pds">'</span></span>,<span class="pl-v">comment.char</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>;<span class="pl-pds">'</span></span>)

<span class="pl-v">score.sentiment</span> <span class="pl-k">=</span> <span class="pl-k">function</span>(<span class="pl-smi">sentences</span>, <span class="pl-smi">pos.words</span>, <span class="pl-smi">neg.words</span>, <span class="pl-v">.progress</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>none<span class="pl-pds">'</span></span>)
{
  require(<span class="pl-smi">plyr</span>)
  require(<span class="pl-smi">stringr</span>)

  <span class="pl-c"># we got a vector of sentences. plyr will handle a list</span>
  <span class="pl-c"># or a vector as an "l" for us</span>
  <span class="pl-c"># we want a simple array ("a") of scores back, so we use </span>
  <span class="pl-c"># "l" + "a" + "ply" = "laply":</span>
  <span class="pl-v">scores</span> <span class="pl-k">=</span> laply(<span class="pl-smi">sentences</span>, <span class="pl-k">function</span>(<span class="pl-smi">sentence</span>, <span class="pl-smi">pos.words</span>, <span class="pl-smi">neg.words</span>) {

    <span class="pl-c"># clean up sentences with R's regex-driven global substitute, gsub():</span>
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> gsub(<span class="pl-s"><span class="pl-pds">'</span>[[:punct:]]<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-pds">'</span></span>, <span class="pl-smi">sentence</span>)
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> gsub(<span class="pl-s"><span class="pl-pds">'</span>[[:cntrl:]]<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-pds">'</span></span>, <span class="pl-smi">sentence</span>)
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> gsub(<span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\\</span>d+<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-pds">'</span></span>, <span class="pl-smi">sentence</span>)
    <span class="pl-c"># and convert to lower case:</span>
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> tolower(<span class="pl-smi">sentence</span>)

    <span class="pl-c"># split into words. str_split is in the stringr package</span>
    <span class="pl-v">word.list</span> <span class="pl-k">=</span> str_split(<span class="pl-smi">sentence</span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\\</span>s+<span class="pl-pds">'</span></span>)
    <span class="pl-c"># sometimes a list() is one level of hierarchy too much</span>
    <span class="pl-v">words</span> <span class="pl-k">=</span> unlist(<span class="pl-smi">word.list</span>)

    <span class="pl-c"># compare our words to the dictionaries of positive &amp; negative terms</span>
    <span class="pl-v">pos.matches</span> <span class="pl-k">=</span> match(<span class="pl-smi">words</span>, <span class="pl-smi">pos.words</span>)
    <span class="pl-v">neg.matches</span> <span class="pl-k">=</span> match(<span class="pl-smi">words</span>, <span class="pl-smi">neg.words</span>)

    <span class="pl-c"># match() returns the position of the matched term or NA</span>
    <span class="pl-c"># we just want a TRUE/FALSE:</span>
    <span class="pl-v">pos.matches</span> <span class="pl-k">=</span> <span class="pl-k">!</span>is.na(<span class="pl-smi">pos.matches</span>)
    <span class="pl-v">neg.matches</span> <span class="pl-k">=</span> <span class="pl-k">!</span>is.na(<span class="pl-smi">neg.matches</span>)

    <span class="pl-c"># and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():</span>
    <span class="pl-v">score</span> <span class="pl-k">=</span> sum(<span class="pl-smi">pos.matches</span>) <span class="pl-k">-</span> sum(<span class="pl-smi">neg.matches</span>)

    <span class="pl-k">return</span>(<span class="pl-smi">score</span>)
  }, <span class="pl-smi">pos.words</span>, <span class="pl-smi">neg.words</span>, <span class="pl-v">.progress</span><span class="pl-k">=</span>.<span class="pl-smi">progress</span> )

  <span class="pl-v">scores.df</span> <span class="pl-k">=</span> <span class="pl-k">data.frame</span>(<span class="pl-v">score</span><span class="pl-k">=</span><span class="pl-smi">scores</span>, <span class="pl-v">text</span><span class="pl-k">=</span><span class="pl-smi">sentences</span>)
  <span class="pl-k">return</span>(<span class="pl-smi">scores.df</span>)
}</pre></div>

<p>Then made subsets of the data based on posts mentioning each bank, names (redacted in text file to NAME), and internet addresses (redacted in text file to INTERNET)</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">df.1000</span><span class="pl-k">$</span><span class="pl-v">FullText</span> <span class="pl-k">=</span> as.character(<span class="pl-smi">df.1000</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>)
<span class="pl-v">df.bankA</span> <span class="pl-k">=</span> <span class="pl-smi">df.1000</span>[<span class="pl-smi">bankA.idx</span>,]
<span class="pl-v">df.bankB</span> <span class="pl-k">=</span> <span class="pl-smi">df.1000</span>[<span class="pl-smi">bankB.idx</span>,]
<span class="pl-v">df.bankC</span> <span class="pl-k">=</span> <span class="pl-smi">df.1000</span>[<span class="pl-smi">bankC.idx</span>,]
<span class="pl-v">df.bankD</span> <span class="pl-k">=</span> <span class="pl-smi">df.1000</span>[<span class="pl-smi">bankD.idx</span>,]
<span class="pl-v">df.names</span> <span class="pl-k">=</span> <span class="pl-smi">df.1000</span>[<span class="pl-smi">name.idx</span>,]
<span class="pl-v">df.internet</span> <span class="pl-k">=</span> <span class="pl-smi">df.1000</span>[<span class="pl-smi">internet.idx</span>,]</pre></div>

<p>Next, calculated sentiment score for each.</p>

<div class="highlight highlight-source-r"><pre><span class="pl-v">df.sent</span> <span class="pl-k">=</span> <span class="pl-smi">df.BankA</span> <span class="pl-c">##or whichever subset to analyze</span>

<span class="pl-v">scores</span> <span class="pl-k">=</span> score.sentiment(<span class="pl-smi">df.sent</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>, <span class="pl-smi">pos</span>, <span class="pl-smi">neg</span>, <span class="pl-v">.progress</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>text<span class="pl-pds">'</span></span>)
<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-v">very.pos</span> <span class="pl-k">=</span> as.numeric(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">score</span> <span class="pl-k">&gt;</span><span class="pl-k">=</span> <span class="pl-c1">2</span>)
<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-v">very.neg</span> <span class="pl-k">=</span> as.numeric(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">score</span> <span class="pl-k">&lt;</span><span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">2</span>)

<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-v">pos</span> <span class="pl-k">=</span> as.numeric(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">score</span> <span class="pl-k">&gt;</span><span class="pl-k">=</span> <span class="pl-c1">1</span>)
<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-v">neg</span> <span class="pl-k">=</span> as.numeric(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">score</span> <span class="pl-k">&gt;</span><span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">1</span>)

<span class="pl-c"># how many very positives and very negatives</span>
<span class="pl-v">numpos</span> <span class="pl-k">=</span> sum(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">very.pos</span>)
<span class="pl-v">numneg</span> <span class="pl-k">=</span> sum(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">very.neg</span>)

<span class="pl-c"># global score</span>
<span class="pl-v">global_score</span> <span class="pl-k">=</span> round( <span class="pl-c1">100</span> <span class="pl-k">*</span> <span class="pl-smi">numpos</span> <span class="pl-k">/</span> (<span class="pl-smi">numpos</span> <span class="pl-k">+</span> <span class="pl-smi">numneg</span>) )</pre></div>

<p>The global scores (a rough measure of general sentiment) are as follows:</p>

<p>All Banks (df.1000): 59
Bank A: 57
Bank B: 56
Bank C: 74
Bank D: 50
Text with “NAME”: 50
Text with “INTERNET”: 55</p>

<p>Next, plots of sentiment scores were generated, separating by media type (Twitter or Facebook).</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-v">mediatype</span> <span class="pl-k">=</span> <span class="pl-smi">df.sent</span><span class="pl-k">$</span><span class="pl-smi">MediaType</span>

<span class="pl-c"># colors</span>
<span class="pl-v">cols</span> <span class="pl-k">=</span> c(<span class="pl-s"><span class="pl-pds">"</span>#7CAE00<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>#00BFC4<span class="pl-pds">"</span></span>)
names(<span class="pl-smi">cols</span>) <span class="pl-k">=</span> c(<span class="pl-s"><span class="pl-pds">"</span>twitter<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>facebook<span class="pl-pds">"</span></span>)

<span class="pl-c"># boxplot</span>
library(<span class="pl-smi">ggplot2</span>)
ggplot(<span class="pl-smi">scores</span>, aes(<span class="pl-v">x</span><span class="pl-k">=</span><span class="pl-smi">mediatype</span>, <span class="pl-v">y</span><span class="pl-k">=</span><span class="pl-smi">score</span>, <span class="pl-v">group</span><span class="pl-k">=</span><span class="pl-smi">mediatype</span>)) <span class="pl-k">+</span>
  geom_boxplot(aes(<span class="pl-v">fill</span><span class="pl-k">=</span><span class="pl-smi">mediatype</span>)) <span class="pl-k">+</span>
  scale_fill_manual(<span class="pl-v">values</span><span class="pl-k">=</span><span class="pl-smi">cols</span>) <span class="pl-k">+</span>
  geom_jitter(<span class="pl-v">colour</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>gray40<span class="pl-pds">"</span></span>,<span class="pl-v">position</span><span class="pl-k">=</span>position_jitter(<span class="pl-v">width</span><span class="pl-k">=</span><span class="pl-c1">0.2</span>), <span class="pl-v">alpha</span><span class="pl-k">=</span><span class="pl-c1">0.3</span>) <span class="pl-k">+</span>
  labs(<span class="pl-v">title</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Media Type's Sentiment Scores: All Banks<span class="pl-pds">"</span></span>) <span class="pl-k">+</span> 
  xlab(<span class="pl-s"><span class="pl-pds">'</span>Media Type<span class="pl-pds">'</span></span>) <span class="pl-k">+</span> ylab(<span class="pl-s"><span class="pl-pds">'</span>Sentiment Score<span class="pl-pds">'</span></span>)

<span class="pl-c"># barplot of average score</span>
<span class="pl-v">meanscore</span> <span class="pl-k">=</span> tapply(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">score</span>, <span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">mediatype</span>, <span class="pl-smi">mean</span>)
<span class="pl-v">df.plot</span> <span class="pl-k">=</span> <span class="pl-k">data.frame</span>(<span class="pl-v">mediatype</span><span class="pl-k">=</span>names(<span class="pl-smi">meanscore</span>), <span class="pl-v">meanscore</span><span class="pl-k">=</span><span class="pl-smi">meanscore</span>)
<span class="pl-smi">df.plot</span><span class="pl-k">$</span><span class="pl-smi">mediatypes</span> <span class="pl-k">&lt;-</span> reorder(<span class="pl-smi">df.plot</span><span class="pl-k">$</span><span class="pl-smi">mediatype</span>, <span class="pl-smi">df.plot</span><span class="pl-k">$</span><span class="pl-smi">meanscore</span>)

ggplot(<span class="pl-smi">df.plot</span>, aes(<span class="pl-v">x</span> <span class="pl-k">=</span> <span class="pl-k">factor</span>(<span class="pl-smi">mediatypes</span>), <span class="pl-v">y</span> <span class="pl-k">=</span> <span class="pl-smi">meanscore</span>, <span class="pl-v">fill</span><span class="pl-k">=</span><span class="pl-smi">mediatypes</span>)) <span class="pl-k">+</span>
  geom_bar(<span class="pl-v">stat</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>identity<span class="pl-pds">"</span></span>) <span class="pl-k">+</span>
  scale_fill_manual(<span class="pl-v">values</span><span class="pl-k">=</span><span class="pl-smi">cols</span>[order(<span class="pl-smi">df.plot</span><span class="pl-k">$</span><span class="pl-smi">meanscore</span>)]) <span class="pl-k">+</span>
  labs(<span class="pl-v">title</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Average Sentiment Score: All Banks<span class="pl-pds">"</span></span>) <span class="pl-k">+</span> 
  xlab(<span class="pl-s"><span class="pl-pds">'</span>Media Type<span class="pl-pds">'</span></span>) <span class="pl-k">+</span> ylab(<span class="pl-s"><span class="pl-pds">'</span>Average Score<span class="pl-pds">'</span></span>)

<span class="pl-c"># barplot of average very positive</span>
<span class="pl-v">mediatype_pos</span> <span class="pl-k">=</span> ddply(<span class="pl-smi">scores</span>, .(<span class="pl-smi">mediatype</span>), <span class="pl-smi">summarise</span>, <span class="pl-v">mean_pos</span><span class="pl-k">=</span>mean(<span class="pl-smi">very.pos</span>))
<span class="pl-smi">mediatype_pos</span><span class="pl-k">$</span><span class="pl-smi">mediatypes</span> <span class="pl-k">&lt;-</span> reorder(<span class="pl-smi">mediatype_pos</span><span class="pl-k">$</span><span class="pl-smi">mediatype</span>, <span class="pl-smi">mediatype_pos</span><span class="pl-k">$</span><span class="pl-smi">mean_pos</span>)

ggplot(<span class="pl-smi">mediatype_pos</span>, aes(<span class="pl-v">x</span> <span class="pl-k">=</span> <span class="pl-k">factor</span>(<span class="pl-smi">mediatype</span>), <span class="pl-v">y</span> <span class="pl-k">=</span> <span class="pl-smi">mean_pos</span>, <span class="pl-v">fill</span><span class="pl-k">=</span><span class="pl-smi">mediatype</span>)) <span class="pl-k">+</span>
  geom_bar(<span class="pl-v">stat</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>identity<span class="pl-pds">"</span></span>) <span class="pl-k">+</span>
  scale_fill_manual(<span class="pl-v">values</span><span class="pl-k">=</span><span class="pl-smi">cols</span>[order(<span class="pl-smi">df.plot</span><span class="pl-k">$</span><span class="pl-smi">meanscore</span>)]) <span class="pl-k">+</span>
  labs(<span class="pl-v">title</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Average Very Positive Sentiment Score: All Banks<span class="pl-pds">"</span></span>) <span class="pl-k">+</span> 
  xlab(<span class="pl-s"><span class="pl-pds">'</span>Media Type<span class="pl-pds">'</span></span>) <span class="pl-k">+</span> ylab(<span class="pl-s"><span class="pl-pds">'</span>Average Score<span class="pl-pds">'</span></span>)

<span class="pl-v">mediatype_neg</span> <span class="pl-k">=</span> ddply(<span class="pl-smi">scores</span>, .(<span class="pl-smi">mediatype</span>), <span class="pl-smi">summarise</span>, <span class="pl-v">mean_neg</span><span class="pl-k">=</span>mean(<span class="pl-smi">very.neg</span>))
<span class="pl-smi">mediatype_neg</span><span class="pl-k">$</span><span class="pl-smi">mediatypes</span> <span class="pl-k">&lt;-</span> reorder(<span class="pl-smi">mediatype_neg</span><span class="pl-k">$</span><span class="pl-smi">mediatype</span>, <span class="pl-smi">mediatype_neg</span><span class="pl-k">$</span><span class="pl-smi">mean_neg</span>)

ggplot(<span class="pl-smi">mediatype_neg</span>, aes(<span class="pl-v">x</span> <span class="pl-k">=</span> <span class="pl-k">factor</span>(<span class="pl-smi">mediatype</span>), <span class="pl-v">y</span> <span class="pl-k">=</span> <span class="pl-smi">mean_neg</span>, <span class="pl-v">fill</span><span class="pl-k">=</span><span class="pl-smi">mediatype</span>)) <span class="pl-k">+</span>
  geom_bar(<span class="pl-v">stat</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>identity<span class="pl-pds">"</span></span>) <span class="pl-k">+</span>
  scale_fill_manual(<span class="pl-v">values</span><span class="pl-k">=</span><span class="pl-smi">cols</span>[order(<span class="pl-smi">df.plot</span><span class="pl-k">$</span><span class="pl-smi">meanscore</span>)]) <span class="pl-k">+</span>
  labs(<span class="pl-v">title</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Average Very Negative Sentiment Score: All Banks<span class="pl-pds">"</span></span>) <span class="pl-k">+</span> 
  xlab(<span class="pl-s"><span class="pl-pds">'</span>Media Type<span class="pl-pds">'</span></span>) <span class="pl-k">+</span> ylab(<span class="pl-s"><span class="pl-pds">'</span>Average Score<span class="pl-pds">'</span></span>)</pre></div>

<p>Each submission will contain a written report with the following sections:
• Deliverable A: Describe your Approach and Methodology, including a visual representation of analytic process flow
• Deliverable B: Discuss the data and its relationship to social conversation drivers
• Deliverable C: Document your code and reference the analytic process flow-diagram from deliverable A
• Deliverable D: Create list of topics and substance you found
• Deliverable E: Create narrative of insights supported by quantitative results (should include graphs or charts)</p>

<h2>
<a id="conclusions" class="anchor" href="#conclusions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusions</h2>

<div class="highlight highlight-source-r"><pre>loading(<span class="pl-smi">texts</span>)</pre></div>

<p><img src="http://i.imgur.com/oGyY7Zo.jpg" alt=""></p>

<h2>
<a id="important-links" class="anchor" href="#important-links" aria-hidden="true"><span class="octicon octicon-link"></span></a>Important Links</h2>

<ul>
<li><a href="http://learn2mine.appspot.com/">Learn2Mine - where you complete assignments</a></li>
<li><a href="http://learn2mine.appspot.com/EnrollClass?key=G5avwmEBUIdo1UTFDGCX">Join Learn2Mine Class</a></li>
<li><a href="http://freyja.cs.cofc.edu/rstudio-learn2mine">RStudio - where you code</a></li>
<li><a href="https://www.dropbox.com/sh/u7rd31jqtkfv9la/AAA85S3odhJ28VrRgkBrNdUia?dl=0">Course Materials</a></li>
<li><a href="https://docs.google.com/presentation/d/1e0AdOUa3nbjkkV-j4ZcG8acG_INjmv42nPkpr5xuGFc/edit?usp=sharing">Schedule, news, and assignments. You must check this regularly</a></li>
</ul>

<h1>
<a id="syllabus" class="anchor" href="#syllabus" aria-hidden="true"><span class="octicon octicon-link"></span></a>Syllabus</h1>

<h2>
<a id="official-course-description" class="anchor" href="#official-course-description" aria-hidden="true"><span class="octicon octicon-link"></span></a>Official Course Description</h2>

<p align="justify">
<a href="http://www.cofc.edu"><img src="http://freyja.cs.cofc.edu/cofc.sepng" height="50" align="right" hspace="10px"> </a>
Introduction to the use of computer based tools for the analysis of large data sets for the purpose of knowledge discovery. Students will learn to understand the Data Science process and the difference between deductive hypothesis-driven and inductive data-driven modeling. Students will have hands-on experience with various on-line analytical processing and data mining software and complete a project using real data.
</p>

<h2>
<a id="our-plan" class="anchor" href="#our-plan" aria-hidden="true"><span class="octicon octicon-link"></span></a>Our plan</h2>

<p>The plan this semester is to work through the analysis of real world datasets provided by the data science website called kaggle.com and from my own personal research. The class will be heavily structured around these projects. In fact, there will be only two examinations (1 midterm and 1 final). These will be on the theory of data science and the algorithms covered throughout class. The most important component of the course will be the practical experience gained as a data scientist, and this will be built upon by exploring:</p>

<p>Targeted data science lessons on concepts discussed in class. The topics will vary from week to week. They are designed to build up your skills to accomplish the next two tasks.
Predicting the survival rate on the titanic (<a href="https://www.kaggle.com/c/titanic-gettingStarted">https://www.kaggle.com/c/titanic-gettingStarted</a>). This is the first data science competition that we will do as a class. As we progress through the class, there will be a number of assignments focused on this prediction task.
Bioinformatics: Next-generation genomics data analysis
Each week will have a consistent schedule. The first class will be traditional lecture style with a heavy emphasis on interactive discussion, where I will go over the theory behind the algorithms and concepts. The second class will be mostly lab style. My goal is to be your guide as you gain experience being a data scientist. Though this time will also be used to teach you the R programming language as well. It is during this second class and out of the classroom that you will gain practical experience as a data scientist. If you have laptops, please bring them to the second class of each week.</p>

<h2>
<a id="course-details" class="anchor" href="#course-details" aria-hidden="true"><span class="octicon octicon-link"></span></a>Course Details</h2>

<h3>
<a id="contact-information" class="anchor" href="#contact-information" aria-hidden="true"><span class="octicon octicon-link"></span></a>Contact Information</h3>

<p>Professor: Dr. Paul Anderson
Office: 313 Harbor Walk East
Office Hours: My door is always open. Even if it isn't, please knock. I always love to hear from students. I have a little sign that I try to keep up in the window to show when I am in the office. Tuesday and Thursday from 2:00 - 3:30 PM are my official hours.
E-mail: <a href="mailto:andersonpe2@cofc.edu">andersonpe2@cofc.edu</a>
Office Phone: 953-8151
Facebook: <a href="mailto:andersonpe2@cofc.edu">andersonpe2@cofc.edu</a>
Facebook group: <a href="https://www.facebook.com/groups/1689269657959552/">https://www.facebook.com/groups/1689269657959552/</a></p>

<h3>
<a id="course-times" class="anchor" href="#course-times" aria-hidden="true"><span class="octicon octicon-link"></span></a>Course Times</h3>

<p>Section 01 - TR 09:55 am-11:10 am in HWEA 334</p>

<p>Section 02 - TR 03:35 pm-04:50 pm in HWEA 300</p>

<h3>
<a id="course-learning-outcomes" class="anchor" href="#course-learning-outcomes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Course (learning) outcomes</h3>

<p>To gain an overview the field of knowledge discovery
To be able to distinguish and translate between data, information, and knowledge
To learn how to store, query, aggregate data in databases
To be able to distinguish problems based on computability
To learn how to implement distributed computing and storage
To apply algorithms for inductive and deductive reasoning
To learn introductory and state-of-the-art data mining algorithms
To apply data mining, statistical inference, and machine learning algorithms to a variety of datasets, including text, image, biological, and health
To apply information filtering on real world datasets
To apply information validation on real world datasets
To apply artificial intelligence concepts to real world datasets
To understand the social, ethical, and legal issues of informatics and data science</p>

<h3>
<a id="grading-policy" class="anchor" href="#grading-policy" aria-hidden="true"><span class="octicon octicon-link"></span></a>Grading Policy</h3>

<p>Midterm - 15%
Final Exam - 15%
Homework - 10%
Programming Assignments and Final Project - 60%
Grading Scale: A: 90-100; B: 80-89; C: 70-79; D: 65-69; F: &lt;65. Plusses and minuses will be used at the discretion of the instructor.</p>

<p>Grading Guidelines: Submitted work requires Analysis, Evaluation, and Creation of ideas, concepts, and materials into various deliverables (e.g., see revised Bloom's Taxonomy and reference below).</p>

<p>The grade of A is for work that involves high-quality achievement in all three Bloom areas.
The grade of B is for work that involves high-quality achievement in at least two Bloom areas, and medium-level achievement in the other.
The grade of C is for work that involves high-quality achievement in at least one Bloom area, and medium-level achievement in the others.
The grade of F is for work that does not meet above criteria.
Reference: Errol Thompson, Andrew Luxton-Reilly, Jacqueline L. Whalley, Minjie Hu, and Phil Robbins. 2008. Bloom's taxonomy for CS assessment. In Proceedings of the tenth conference on Australasian computing education - Volume 78 (ACE '08), Simon Hamilton and Margaret Hamilton (Eds.), Vol. 78. Australian Computer Society, Inc., Darlinghurst, Australia, Australia, 155-161.</p>

<h3>
<a id="homework-policy" class="anchor" href="#homework-policy" aria-hidden="true"><span class="octicon octicon-link"></span></a>Homework Policy</h3>

<p>Written homework will placed under my office door by 5 PM on the due date. No late homework will be accepted. Cheating/sharing will result in a zero on the assignment and a report to the judicial board.</p>

<h3>
<a id="programming-assignments" class="anchor" href="#programming-assignments" aria-hidden="true"><span class="octicon octicon-link"></span></a>Programming Assignments</h3>

<p>Programming assignments will be submitted through the Learn2Mine environment. There will be a combination of in-class lab assignments, and out of programming assignments.</p>

<h3>
<a id="honor-code" class="anchor" href="#honor-code" aria-hidden="true"><span class="octicon octicon-link"></span></a>Honor Code</h3>

<p>You must do your work alone (or with your teammates, for group assignments).
You must identify your sources of material and inspiration. It is a violation of the honor code to present someone else's work or ideas as your own.
In any course deliverable, you must always identify the person(s) that helped you (directly or indirectly), if any, and explain their contribution to your work.
Also see the College of Charleston Student Handbook, especially sections on The Honor Code (p. 11), and Student Code of Conduct (p. 12). There is other useful information there.
Classroom Policies</p>

<p>You are expected to take good notes during class.
You are expected to participate in class with questions and invited discussion.
You are expected to attend all classes. The grade 'WA' will be given for excessive (&gt;= 3) absences. If you miss class, you must get an absence memo from the Associate Dean of Students Office; also, you are responsible for announcements made in class, assignment due dates, etc.
You should turn off all electronic devices (e.g., cell phones, pagers, etc.).
In summary, you should contribute positively to the classroom learning experience, and respect your classmates right to learn (see College of Charleston Student Handbook, section on Classroom Code of Conduct (p. 58)).
Late Policy</p>

<p>No late days will be allowed without an excuse. Falling behind on assignments will make it difficult to achieve the learning outcomes of this course.</p>

<h3>
<a id="facebook-group" class="anchor" href="#facebook-group" aria-hidden="true"><span class="octicon octicon-link"></span></a>Facebook Group</h3>

<p>You are required to join the Facebook Group. The majority of class related discussions will be carried out in this forum.</p>

<p><a href="https://www.facebook.com/groups/1689269657959552/">Join the Facebook group here</a></p>

<h2>
<a id="midterm" class="anchor" href="#midterm" aria-hidden="true"><span class="octicon octicon-link"></span></a>Midterm</h2>

<p>The is scheduled for Tuesday, October 27th</p>

<h2>
<a id="final" class="anchor" href="#final" aria-hidden="true"><span class="octicon octicon-link"></span></a>Final</h2>

<p>The final exam will be take home.</p>

<p>The final exam time will be used for final project presentations.</p>

<p>Section 01 - Saturday, December 12th from 8 - 11 AM</p>

<p>Section 02 - Thursday, December 10th from 4 - 7 PM</p>

<h1>
<a id="anderson-data-science-research-lab" class="anchor" href="#anderson-data-science-research-lab" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="http://anderson-lab.github.io/">Anderson Data Science Research Lab</a>
</h1>

<p align="justify">
<a href="http://anderson-lab.github.io/"><img src="http://freyja.cs.cofc.edu/Paul-labs-logo.png" alt="Data Science Research Lab" height="100" align="right" hspace="10px"></a>
The Anderson Data Science Research Lab specializes in applying data mining, machine learning, and artificial intelligence to the fields of bioinformatics, genomics, and metabolomics. We develop algorithms and software to tackle some of the most challenging and interesting data intensive problems in the life sciences. Our research interests include data science, big data, pattern analysis in high-dimensionality data sets, evolutionary computation and optimization, machine learning, computational genomics, cloud computing, computational metabolomics, and eScience. We currently have multidisciplinary projects underway in metabolomics, human cognition, toxicology, marine biology, medical genomics, biomedical informatics, and marine genomics.
</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/kayat30/wells-fargo-analytics">Wells Fargo Analytics Competition</a> is maintained by <a href="https://github.com/kayat30">kayat30</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
